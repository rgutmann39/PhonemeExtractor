{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":180,"status":"ok","timestamp":1639667443385,"user":{"displayName":"Sahas D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFhTlCEcqzOdyxuFJOFIBVlqcxwFeNCZ0oVVfdng=s64","userId":"10479330133775136174"},"user_tz":300},"id":"ujH-VHtsOOoy"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1390,"status":"ok","timestamp":1639667444772,"user":{"displayName":"Sahas D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFhTlCEcqzOdyxuFJOFIBVlqcxwFeNCZ0oVVfdng=s64","userId":"10479330133775136174"},"user_tz":300},"id":"WKLqYVqQOXD_","outputId":"a2ac93e1-1d2a-495e-cb22-48d1752e45b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":236,"status":"ok","timestamp":1639667445006,"user":{"displayName":"Sahas D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFhTlCEcqzOdyxuFJOFIBVlqcxwFeNCZ0oVVfdng=s64","userId":"10479330133775136174"},"user_tz":300},"id":"h5ImY5dOOaou","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2dd2ddfe-489c-4198-883c-1582f9181b2c"},"outputs":[{"output_type":"stream","name":"stdout","text":["drive/My Drive/college/595_final_project\n"]}],"source":["import os\n","import sys\n","\n","WORKSPACE_DIR = 'college/595_final_project'\n","WORKSPACE_PATH = os.path.join('drive', 'My Drive', WORKSPACE_DIR)\n","sys.path.append(WORKSPACE_PATH)\n","print(WORKSPACE_PATH)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6748,"status":"ok","timestamp":1639667451752,"user":{"displayName":"Sahas D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFhTlCEcqzOdyxuFJOFIBVlqcxwFeNCZ0oVVfdng=s64","userId":"10479330133775136174"},"user_tz":300},"id":"NYjgqG0QPJp2","outputId":"20231ec2-584c-46c9-8b8d-f61736026f26"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.16.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.8.2)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.2.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.11.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.4.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.13)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.8)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (5.2.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.6.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"]}],"source":["!pip install datasets"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1229,"status":"ok","timestamp":1639667453204,"user":{"displayName":"Sahas D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFhTlCEcqzOdyxuFJOFIBVlqcxwFeNCZ0oVVfdng=s64","userId":"10479330133775136174"},"user_tz":300},"id":"0zV6_LzLOe1N"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch import optim\n","from tqdm import tqdm\n","import torch.nn.functional as F\n","import time\n","import math\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","import numpy as np\n","import random\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["1a1541c693d0472a9be5aa3b7b57f0da","e7d49009296242778e52c36e25d40450","29eccf4430534569958a92a052d86a71","566e5b5dcbe6439fb45bfdc5c5fabe8c","c621b8e8e2d742c080a8e5b3199d8f97","dc336f0e6f534ecba29081b578ecd168","eee08d6eab2d45389054b7ce49570fdf","5c515fdaca274a65bec45e088ad99133","37b28ef5a3de47e78f16bd5400dce6b1","dfb1aaf51bc94b719f9e652f649a918e","bfa746976e3a46a29fc4493d5552b4b0"]},"id":"mNsKdHhvOoJt","outputId":"251460d0-69f7-4ad4-ccb9-c6fab6894518","executionInfo":{"status":"ok","timestamp":1639667454263,"user_tz":300,"elapsed":1061,"user":{"displayName":"Sahas D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFhTlCEcqzOdyxuFJOFIBVlqcxwFeNCZ0oVVfdng=s64","userId":"10479330133775136174"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Reusing dataset timit_asr (drive/My Drive/college/595_final_project/data/timit_asr/clean/2.0.1/5bebea6cd9df0fc2c8c871250de23293a94c1dc49324182b330b6759ae6718f8)\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1a1541c693d0472a9be5aa3b7b57f0da","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{}}],"source":["from datasets import load_dataset\n","timit_dataset = load_dataset('timit_asr', cache_dir=\"drive/My Drive/college/595_final_project/data\")"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"qRQpQqfhZBrO","executionInfo":{"status":"ok","timestamp":1639667454263,"user_tz":300,"elapsed":2,"user":{"displayName":"Sahas D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFhTlCEcqzOdyxuFJOFIBVlqcxwFeNCZ0oVVfdng=s64","userId":"10479330133775136174"}}},"outputs":[],"source":["# GLOBALS\n","MAX_LEN = 72\n","\n","# MODEL HYPERPARAMS\n","ENC_EMB_DIM = 256\n","DEC_EMB_DIM = 256\n","ENC_HID_DIM = 512\n","DEC_HID_DIM = 512\n","ENC_DROPOUT = 0.5\n","DEC_DROPOUT = 0.5\n","\n","# TRAINING PARAMS\n","BATCH_SIZE = 128\n","N_EPOCHS = 35\n","\n","# REGULARIZATION PARAMATERS\n","ENC_DROPOUT = 0.5\n","DEC_DROPOUT = 0.5\n","CLIP = 1"]},{"cell_type":"code","source":["def map_phonemes_to_words(dp):\n","  word_idx = 0\n","  phoneme_idx = 0\n","  mappings = []\n","  for word_stop_time in dp['word_detail']['stop']:\n","    while word_stop_time >= dp['phonetic_detail']['stop'][phoneme_idx]:\n","      mappings.append(word_idx)\n","      phoneme_idx += 1\n","    word_idx += 1\n","\n","  while phoneme_idx < len(dp['phonetic_detail']['utterance']):\n","    mappings.append(word_idx-1)\n","    phoneme_idx += 1\n","\n","  phonetic_len = len(dp['phonetic_detail']['utterance'])\n","  assert len(mappings) == len(dp['phonetic_detail']['utterance']), f'ASSERT FAILED: mapping len: {len(mappings)} vs phoneme len: {phonetic_len}'\n","  return mappings"],"metadata":{"id":"cBKV1hKG6Yj2","executionInfo":{"status":"ok","timestamp":1639667454263,"user_tz":300,"elapsed":2,"user":{"displayName":"Sahas D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFhTlCEcqzOdyxuFJOFIBVlqcxwFeNCZ0oVVfdng=s64","userId":"10479330133775136174"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","execution_count":9,"metadata":{"id":"aFH5zPxxQzo_","executionInfo":{"status":"ok","timestamp":1639667457315,"user_tz":300,"elapsed":3054,"user":{"displayName":"Sahas D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFhTlCEcqzOdyxuFJOFIBVlqcxwFeNCZ0oVVfdng=s64","userId":"10479330133775136174"}}},"outputs":[],"source":["def preprocess_timit_data(data):\n","  pairs = []\n","  for dp in data:\n","    word_seq = dp['word_detail']['utterance']\n","    phoneme_seq = dp['phonetic_detail']['utterance']\n","    phoneme_word_mappings = map_phonemes_to_words(dp)\n","    pairs.append((word_seq, phoneme_seq, phoneme_word_mappings))\n","  return pairs\n","\n","train_pairs = preprocess_timit_data(timit_dataset['train'])\n","# val_pairs = preprocess_timit_data(timit_dataset['train'])[0:100]\n","test_pairs = preprocess_timit_data(timit_dataset['test'])\n","\n","# dev_train_pairs = preprocess_timit_data(timit_dataset['train'])[:100]\n","# dev_val_pairs = preprocess_timit_data(timit_dataset['train'])[0:10]"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"ITsQNcfZUYd8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639667457674,"user_tz":300,"elapsed":362,"user":{"displayName":"Sahas D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFhTlCEcqzOdyxuFJOFIBVlqcxwFeNCZ0oVVfdng=s64","userId":"10479330133775136174"}},"outputId":"2779a0bc-e9ae-438a-c0bb-0c4bc191d285"},"outputs":[{"output_type":"stream","name":"stdout","text":["training points: 4620, num input tokens: 4897, num output tokens: 65\n"]}],"source":["from token_encoder import TokenEncoder, build_io_token_encodings\n","\n","word_encoder = TokenEncoder(MAX_LEN)\n","phoneme_encoder = TokenEncoder(MAX_LEN)\n","build_io_token_encodings(word_encoder, phoneme_encoder, train_pairs)\n","print(f'training points: {len(train_pairs)}, num input tokens: {word_encoder.n_tokens}, num output tokens: {phoneme_encoder.n_tokens}')"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"yv4ObuxFbPn5","executionInfo":{"status":"ok","timestamp":1639667457674,"user_tz":300,"elapsed":3,"user":{"displayName":"Sahas D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFhTlCEcqzOdyxuFJOFIBVlqcxwFeNCZ0oVVfdng=s64","userId":"10479330133775136174"}}},"outputs":[],"source":["def vectorize_seq(token_encoder, sequence):\n","  indexes = [token_encoder.bos_token_id] + [token_encoder.get_token_index(token) for token in sequence] + [token_encoder.eos_token_id]\n","  if len(indexes) < MAX_LEN:\n","    indexes = indexes + [token_encoder.pad_token_id] * (MAX_LEN - len(indexes))\n","  else:\n","    indexes = indexes[:MAX_LEN]\n","  return torch.tensor(indexes, dtype=torch.long, device=DEVICE)\n","\n","def vectorize_mappings(indexes):\n","  indexes = [0] + [i + 1 for i in indexes] + [indexes[-1]+1]\n","  if len(indexes) < MAX_LEN:\n","    indexes = indexes + [MAX_LEN+1] * (MAX_LEN - len(indexes))\n","  else:\n","    indexes = indexes[:MAX_LEN]\n","  return torch.tensor(indexes, dtype=torch.long, device=DEVICE)\n","\n","\n","def vectorize_pair(pair):\n","  word_vector = vectorize_seq(word_encoder, pair[0])\n","  phoneme_vector = vectorize_seq(phoneme_encoder, pair[1])\n","  phone_word_mapping_vector = vectorize_mappings(pair[2])\n","  return word_vector, phoneme_vector, phone_word_mapping_vector"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"9CknOIsXdC2T","executionInfo":{"status":"ok","timestamp":1639667457847,"user_tz":300,"elapsed":175,"user":{"displayName":"Sahas D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFhTlCEcqzOdyxuFJOFIBVlqcxwFeNCZ0oVVfdng=s64","userId":"10479330133775136174"}}},"outputs":[],"source":["from torch.utils.data import TensorDataset, DataLoader\n","\n","def build_dataset(pairs):\n","  word_vecs = torch.ones((len(pairs), MAX_LEN), dtype=torch.long)\n","  phoneme_vecs = torch.ones((len(pairs), MAX_LEN), dtype=torch.long)\n","  phoneme_word_mapping_vecs = torch.ones((len(pairs), MAX_LEN), dtype=torch.long)\n","  for idx, pair in enumerate(pairs):\n","    word_vec, phoneme_vec, mapping_vec = vectorize_pair(pair)\n","    word_vecs[idx] = word_vec\n","    phoneme_vecs[idx] = phoneme_vec\n","    phoneme_word_mapping_vecs[idx] = mapping_vec\n","\n","  return TensorDataset(word_vecs, phoneme_vecs, phoneme_word_mapping_vecs)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"u8AGGCg7hXhV","executionInfo":{"status":"ok","timestamp":1639667457847,"user_tz":300,"elapsed":2,"user":{"displayName":"Sahas D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFhTlCEcqzOdyxuFJOFIBVlqcxwFeNCZ0oVVfdng=s64","userId":"10479330133775136174"}}},"outputs":[],"source":["def init_weights(m):\n","    for name, param in m.named_parameters():\n","        if 'weight' in name:\n","            nn.init.normal_(param.data, mean=0, std=0.01)\n","        else:\n","            nn.init.constant_(param.data, 0)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"uokkDO-1hmMj","executionInfo":{"status":"ok","timestamp":1639667458020,"user_tz":300,"elapsed":175,"user":{"displayName":"Sahas D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFhTlCEcqzOdyxuFJOFIBVlqcxwFeNCZ0oVVfdng=s64","userId":"10479330133775136174"}}},"outputs":[],"source":["def train(model, iterator, optimizer, vocab_criterion, index_critereon, clip):    \n","  model.train()\n","  \n","  epoch_loss = 0\n","  for i, batch in enumerate(iterator):\n","      \n","    src = batch[0].to(DEVICE).permute(1, 0) # (seq_len, batch_size)\n","    trg = batch[1].to(DEVICE).permute(1, 0) # (seq_len, batch_size)\n","    true_mappings = batch[2].to(DEVICE).permute(1, 0) # (seq_len, batch_size)\n","\n","    \n","    optimizer.zero_grad()\n","    \n","    output, output_mappings = model(src, trg)\n","    \n","    #trg = [trg len, batch size]\n","    #output = [trg len, batch size, output dim]\n","    #output_mappings = [seq_len, batch_size, MAX_LEN]\n","\n","    \n","    output_dim = output.shape[-1]\n","    \n","    output = output[1:].reshape(-1, output_dim)\n","    trg = trg[1:].reshape(-1)\n","\n","    output_mappings = output_mappings[1:].reshape(-1, model.max_len)\n","    true_mappings = true_mappings[1:].reshape(-1)     \n","\n","    \n","    #trg = [(trg len - 1) * batch size]\n","    #output = [(trg len - 1) * batch size, output dim]\n","    \n","    loss = vocab_criterion(output, trg) # + index_critereon(output_mappings, true_mappings)\n","    \n","    loss.backward()\n","    \n","    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","    \n","    optimizer.step()\n","    \n","    epoch_loss += loss.item()\n","        \n","  return epoch_loss / len(iterator)\n"]},{"cell_type":"code","source":["from nltk.translate import bleu\n","from nltk.translate.bleu_score import SmoothingFunction\n","\n","def edit_score(pred, truth, padding_token = None):\n","    # if the lists are padded, then remove the padding before calculating edit distance\n","    if padding_token:\n","        if padding_token in pred:\n","            pred = pred[:pred.index(padding_token)]\n","\n","        if padding_token in truth:\n","            truth = truth[:pred.index(padding_token)]\n","\n","        print(pred, truth)\n","\n","    m = len(pred)\n","    n = len(truth)\n","\n","    # Create a table to store results of subproblems\n","    dp = [[0 for x in range(n + 1)] for x in range(m + 1)]\n","  \n","    # Fill d[][] in bottom up manner\n","    for i in range(m + 1):\n","        for j in range(n + 1):\n","  \n","            # If first list is empty, only option is to\n","            # insert all elements of second list\n","            if i == 0:\n","                dp[i][j] = j    # Min. operations = j\n","  \n","            # If second list is empty, only option is to\n","            # remove all elements of second list\n","            elif j == 0:\n","                dp[i][j] = i    # Min. operations = i\n","  \n","            # If last elements are same, ignore last char\n","            # and recur for remaining list\n","\n","            elif pred[i - 1] == truth[j - 1]:\n","                dp[i][j] = dp[i - 1][j - 1]\n","  \n","            # If last elements are different, consider all\n","            # possibilities and find minimum\n","            else:\n","                dp[i][j] = 1 + min(dp[i][j - 1],        # Insert\n","                                   dp[i - 1][j],        # Remove\n","                                   dp[i - 1][j - 1])    # Replace\n","  \n","    # normalize the edit distance by dividing the number edit distance by the the length of truth\n","    return dp[m][n] / n\n","\n","def epoch_time(start_time, end_time):\n","  elapsed_time = end_time - start_time\n","  elapsed_mins = int(elapsed_time / 60)\n","  elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","  return elapsed_mins, elapsed_secs\n","\n","def accuracy_fn(ref, pred, index=None):\n","  if index:\n","    ref = ref[: min(len(ref), index)]\n","    pred = pred[: min(len(pred), index)]\n","  if len(ref) > len(pred):\n","    pred = pred + [-1] * (len(ref) - len(pred))\n","  if len(pred) > len(ref):\n","    pred = pred[: len(pred)]\n","  return sum(1 for x,y in zip(ref, pred) if x == y) / len(ref)   \n","\n","def evaluate(model, dataloader, vocab_criterion, index_critereon):\n","\n","  smoothie = SmoothingFunction().method4\n","  \n","  bleu_score = 0\n","  phoneme_accuracy = 0\n","  vocab_loss = 0\n","  index_loss = 0\n","  num_datapoints = 0\n","  phoneme_edit = 0\n","\n","  model.eval()\n","  with torch.no_grad():\n","    for i, batch in enumerate(dataloader):\n","      src = batch[0].to(DEVICE).permute(1, 0) # (seq_len, batch_size)\n","      trg = batch[1].to(DEVICE).permute(1, 0) # (seq_len, batch_size)\n","      true_mappings = batch[2].to(DEVICE).permute(1, 0)\n","\n","      output, output_mappings = model(src, trg, 0) #turn off teacher forcing\n","      output_dim = output.shape[-1]\n","      \n","      vocab_loss += vocab_criterion(output[1:].reshape(-1, output_dim), trg[1:].reshape(-1))\n","      index_loss += index_critereon(output_mappings[1:].reshape(-1, model.max_len), true_mappings[1:].reshape(-1)     )\n","\n","      output = output[1:].permute(1, 0, 2) # (batch_size, seq_len, output_vocab_size)\n","      output = output.argmax(-1) # (seq_len, batch_size)\n","      trg = trg[1:].permute(1, 0) # (batch_size, seq_len)\n","\n","      output_mappings =  output_mappings[1:].permute(1, 0, 2)\n","      output_mappings = output_mappings.argmax(-1) # (seq_len, batch_size)\n","      trg_mappings = batch[2].to(DEVICE)[1:]\n","\n","\n","      for j in range(len(batch[0])):\n","        num_datapoints += 1\n","\n","        predicted_sequence = phoneme_encoder.decode_sequence(output[j].tolist())\n","        target_sequence = phoneme_encoder.decode_sequence(trg[j].tolist())[1:]\n","\n","        if phoneme_encoder.eos_token in predicted_sequence:\n","          predicted_sequence = predicted_sequence[:predicted_sequence.index(phoneme_encoder.eos_token)][1:]\n","        target_len = len(target_sequence)\n","        if phoneme_encoder.eos_token in target_sequence:\n","          target_len = target_sequence.index(phoneme_encoder.eos_token)\n","          target_sequence = target_sequence[:target_len]  \n","        bleu_score += bleu([target_sequence], predicted_sequence, smoothing_function=smoothie)\n","        phoneme_accuracy += accuracy_fn(target_sequence, predicted_sequence)\n","        # print('target_seq: ', phoneme_encoder.decode_sequence(trg[j].tolist())[1:])\n","        phoneme_edit += edit_score(predicted_sequence, target_sequence)\n","  \n","  return {\n","      'phoneme_acc': phoneme_accuracy/num_datapoints, \n","      'phoneme_bleu': bleu_score/num_datapoints,\n","      'phoneme_edit': phoneme_edit/num_datapoints,\n","      'vocab_loss': vocab_loss.cpu().numpy() / len(dataloader)\n","  }\n","\n","\n","def generate_samples(model, dataloader):\n","\n","  smoothie = SmoothingFunction().method4\n","\n","  samples = []\n","\n","  model.eval()\n","  with torch.no_grad():\n","    for i, batch in enumerate(dataloader):\n","      src = batch[0].to(DEVICE).permute(1, 0) # (seq_len, batch_size)\n","      trg = batch[1].to(DEVICE).permute(1, 0) # (seq_len, batch_size)\n","      true_mappings = batch[2].to(DEVICE).permute(1, 0)\n","\n","      output, output_mappings = model(src, trg, 0) #turn off teacher forcing\n","      output_dim = output.shape[-1]\n","\n","      output = output[1:].permute(1, 0, 2) # (batch_size, seq_len, output_vocab_size)\n","      output = output.argmax(-1) # (seq_len, batch_size)\n","      trg = trg[1:].permute(1, 0) # (batch_size, seq_len)\n","\n","      output_mappings =  output_mappings[1:].permute(1, 0, 2)\n","      output_mappings = output_mappings.argmax(-1) # (seq_len, batch_size)\n","      trg_mappings = batch[2].to(DEVICE)[1:]\n","\n","\n","      for j in range(len(batch[0])):\n","\n","        predicted_sequence = phoneme_encoder.decode_sequence(output[j].tolist())[1:]\n","        target_sequence = phoneme_encoder.decode_sequence(trg[j].tolist())[1:]\n","\n","        if phoneme_encoder.eos_token in predicted_sequence:\n","          predicted_sequence = predicted_sequence[:predicted_sequence.index(phoneme_encoder.eos_token)]\n","        target_len = len(target_sequence)\n","        if phoneme_encoder.eos_token in target_sequence:\n","          target_len = target_sequence.index(phoneme_encoder.eos_token)\n","          target_sequence = target_sequence[:target_len]   \n","\n","        bleu_score = bleu([target_sequence], predicted_sequence, smoothing_function=smoothie)\n","        phoneme_accuracy = accuracy_fn(target_sequence, predicted_sequence)\n","        phoneme_edit = edit_score(target_sequence, predicted_sequence)\n","\n","        samples.append({\n","            'target': target_sequence,\n","            'predicted': predicted_sequence,\n","            'phoneme_accuracy': phoneme_accuracy,\n","            'phoneme_edit': phoneme_edit,\n","            'bleu_score': bleu_score\n","        })        \n","  \n","  return samples\n"],"metadata":{"id":"j5DFRjZDSslS","executionInfo":{"status":"ok","timestamp":1639667743251,"user_tz":300,"elapsed":514,"user":{"displayName":"Sahas D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFhTlCEcqzOdyxuFJOFIBVlqcxwFeNCZ0oVVfdng=s64","userId":"10479330133775136174"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","execution_count":23,"metadata":{"id":"Jt_xy3_Dj3tU","executionInfo":{"status":"ok","timestamp":1639667750786,"user_tz":300,"elapsed":1431,"user":{"displayName":"Sahas D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFhTlCEcqzOdyxuFJOFIBVlqcxwFeNCZ0oVVfdng=s64","userId":"10479330133775136174"}}},"outputs":[],"source":["train_dataset = build_dataset(train_pairs)\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n","eval_dataset = build_dataset(test_pairs)\n","eval_loader = DataLoader(eval_dataset, batch_size=BATCH_SIZE) "]},{"cell_type":"code","execution_count":24,"metadata":{"id":"CNiDbLoQj4HG","executionInfo":{"status":"ok","timestamp":1639667751175,"user_tz":300,"elapsed":393,"user":{"displayName":"Sahas D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFhTlCEcqzOdyxuFJOFIBVlqcxwFeNCZ0oVVfdng=s64","userId":"10479330133775136174"}}},"outputs":[],"source":["from phoneme_lstm import Encoder, Decoder, Seq2Seq, Attention\n","\n","attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n","enc = Encoder(word_encoder.n_tokens, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n","dec = Decoder(phoneme_encoder.n_tokens, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn, MAX_LEN+1)\n","\n","model = Seq2Seq(enc, dec, MAX_LEN+1, DEVICE).to(DEVICE)\n","\n","model.apply(init_weights)\n","optimizer = optim.Adam(model.parameters())\n","vocab_criterion = nn.CrossEntropyLoss(ignore_index = phoneme_encoder.pad_token_id)\n","index_criterion = nn.CrossEntropyLoss(ignore_index = MAX_LEN+1)"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"TzXzApfyij30","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639668979032,"user_tz":300,"elapsed":1226998,"user":{"displayName":"Sahas D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFhTlCEcqzOdyxuFJOFIBVlqcxwFeNCZ0oVVfdng=s64","userId":"10479330133775136174"}},"outputId":"488d0e49-1d3e-4eaa-9157-6a0798fb5a6e"},"outputs":[{"output_type":"stream","name":"stderr","text":["  3%|▎         | 1/35 [00:35<19:54, 35.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 01 | Time: 0m 35s\n","\tTrain Loss: 3.847 | Train PPL:  46.868\n","\t Val. Loss: 3.709 |  Val. PPL:  40.809\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 2/35 [01:10<19:22, 35.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 02 | Time: 0m 35s\n","\tTrain Loss: 3.419 | Train PPL:  30.537\n","\t Val. Loss: 3.754 |  Val. PPL:  42.712\n"]},{"output_type":"stream","name":"stderr","text":["\r  9%|▊         | 3/35 [01:45<18:48, 35.26s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 03 | Time: 0m 35s\n","\tTrain Loss: 3.098 | Train PPL:  22.157\n","\t Val. Loss: 3.609 |  Val. PPL:  36.921\n"]},{"output_type":"stream","name":"stderr","text":["\r 11%|█▏        | 4/35 [02:20<18:12, 35.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 04 | Time: 0m 35s\n","\tTrain Loss: 2.898 | Train PPL:  18.143\n","\t Val. Loss: 3.623 |  Val. PPL:  37.456\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 5/35 [02:55<17:34, 35.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 05 | Time: 0m 35s\n","\tTrain Loss: 2.804 | Train PPL:  16.516\n","\t Val. Loss: 3.626 |  Val. PPL:  37.561\n"]},{"output_type":"stream","name":"stderr","text":["\r 17%|█▋        | 6/35 [03:30<16:54, 34.98s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 06 | Time: 0m 34s\n","\tTrain Loss: 2.780 | Train PPL:  16.118\n","\t Val. Loss: 3.644 |  Val. PPL:  38.252\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 7/35 [04:05<16:19, 34.99s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 07 | Time: 0m 35s\n","\tTrain Loss: 2.742 | Train PPL:  15.519\n","\t Val. Loss: 3.647 |  Val. PPL:  38.352\n"]},{"output_type":"stream","name":"stderr","text":["\r 23%|██▎       | 8/35 [04:40<15:45, 35.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 08 | Time: 0m 35s\n","\tTrain Loss: 2.697 | Train PPL:  14.843\n","\t Val. Loss: 3.686 |  Val. PPL:  39.866\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 9/35 [05:15<15:11, 35.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 09 | Time: 0m 35s\n","\tTrain Loss: 2.680 | Train PPL:  14.583\n","\t Val. Loss: 3.710 |  Val. PPL:  40.873\n"]},{"output_type":"stream","name":"stderr","text":["\r 29%|██▊       | 10/35 [05:50<14:34, 34.99s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 10 | Time: 0m 34s\n","\tTrain Loss: 2.662 | Train PPL:  14.319\n","\t Val. Loss: 3.691 |  Val. PPL:  40.075\n"]},{"output_type":"stream","name":"stderr","text":["\r 31%|███▏      | 11/35 [06:25<14:00, 35.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 11 | Time: 0m 35s\n","\tTrain Loss: 2.647 | Train PPL:  14.115\n","\t Val. Loss: 3.729 |  Val. PPL:  41.627\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 12/35 [07:01<13:27, 35.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 12 | Time: 0m 35s\n","\tTrain Loss: 2.593 | Train PPL:  13.364\n","\t Val. Loss: 3.825 |  Val. PPL:  45.832\n"]},{"output_type":"stream","name":"stderr","text":["\r 37%|███▋      | 13/35 [07:36<12:52, 35.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 13 | Time: 0m 35s\n","\tTrain Loss: 2.562 | Train PPL:  12.965\n","\t Val. Loss: 3.804 |  Val. PPL:  44.878\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 14/35 [08:11<12:18, 35.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 14 | Time: 0m 35s\n","\tTrain Loss: 2.510 | Train PPL:  12.300\n","\t Val. Loss: 3.844 |  Val. PPL:  46.719\n"]},{"output_type":"stream","name":"stderr","text":["\r 43%|████▎     | 15/35 [08:46<11:42, 35.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 15 | Time: 0m 35s\n","\tTrain Loss: 2.473 | Train PPL:  11.858\n","\t Val. Loss: 3.844 |  Val. PPL:  46.727\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 16/35 [09:21<11:06, 35.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 16 | Time: 0m 34s\n","\tTrain Loss: 2.420 | Train PPL:  11.243\n","\t Val. Loss: 3.894 |  Val. PPL:  49.129\n"]},{"output_type":"stream","name":"stderr","text":["\r 49%|████▊     | 17/35 [09:56<10:30, 35.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 17 | Time: 0m 34s\n","\tTrain Loss: 2.357 | Train PPL:  10.555\n","\t Val. Loss: 3.895 |  Val. PPL:  49.178\n"]},{"output_type":"stream","name":"stderr","text":["\r 51%|█████▏    | 18/35 [10:31<09:54, 34.98s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 18 | Time: 0m 34s\n","\tTrain Loss: 2.253 | Train PPL:   9.518\n","\t Val. Loss: 3.971 |  Val. PPL:  53.017\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 19/35 [11:06<09:19, 34.97s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 19 | Time: 0m 34s\n","\tTrain Loss: 2.185 | Train PPL:   8.895\n","\t Val. Loss: 4.009 |  Val. PPL:  55.092\n"]},{"output_type":"stream","name":"stderr","text":["\r 57%|█████▋    | 20/35 [11:41<08:44, 34.98s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 20 | Time: 0m 35s\n","\tTrain Loss: 2.121 | Train PPL:   8.335\n","\t Val. Loss: 4.018 |  Val. PPL:  55.602\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 21/35 [12:16<08:10, 35.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 21 | Time: 0m 35s\n","\tTrain Loss: 2.039 | Train PPL:   7.682\n","\t Val. Loss: 4.099 |  Val. PPL:  60.282\n"]},{"output_type":"stream","name":"stderr","text":["\r 63%|██████▎   | 22/35 [12:51<07:35, 35.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 22 | Time: 0m 34s\n","\tTrain Loss: 1.969 | Train PPL:   7.161\n","\t Val. Loss: 4.094 |  Val. PPL:  59.973\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 23/35 [13:26<07:00, 35.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 23 | Time: 0m 35s\n","\tTrain Loss: 1.851 | Train PPL:   6.364\n","\t Val. Loss: 4.137 |  Val. PPL:  62.639\n"]},{"output_type":"stream","name":"stderr","text":["\r 69%|██████▊   | 24/35 [14:01<06:24, 35.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 24 | Time: 0m 34s\n","\tTrain Loss: 1.806 | Train PPL:   6.089\n","\t Val. Loss: 4.220 |  Val. PPL:  68.024\n"]},{"output_type":"stream","name":"stderr","text":["\r 71%|███████▏  | 25/35 [14:36<05:49, 34.98s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 25 | Time: 0m 34s\n","\tTrain Loss: 1.731 | Train PPL:   5.649\n","\t Val. Loss: 4.248 |  Val. PPL:  69.975\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 26/35 [15:11<05:14, 34.99s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 26 | Time: 0m 34s\n","\tTrain Loss: 1.662 | Train PPL:   5.272\n","\t Val. Loss: 4.240 |  Val. PPL:  69.418\n"]},{"output_type":"stream","name":"stderr","text":["\r 77%|███████▋  | 27/35 [15:46<04:40, 35.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 27 | Time: 0m 35s\n","\tTrain Loss: 1.643 | Train PPL:   5.169\n","\t Val. Loss: 4.243 |  Val. PPL:  69.590\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 28/35 [16:21<04:05, 35.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 28 | Time: 0m 35s\n","\tTrain Loss: 1.551 | Train PPL:   4.718\n","\t Val. Loss: 4.244 |  Val. PPL:  69.661\n"]},{"output_type":"stream","name":"stderr","text":["\r 83%|████████▎ | 29/35 [16:56<03:30, 35.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 29 | Time: 0m 34s\n","\tTrain Loss: 1.543 | Train PPL:   4.679\n","\t Val. Loss: 4.299 |  Val. PPL:  73.615\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 30/35 [17:31<02:54, 34.95s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 30 | Time: 0m 34s\n","\tTrain Loss: 1.542 | Train PPL:   4.673\n","\t Val. Loss: 4.357 |  Val. PPL:  78.015\n"]},{"output_type":"stream","name":"stderr","text":["\r 89%|████████▊ | 31/35 [18:06<02:19, 35.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 31 | Time: 0m 35s\n","\tTrain Loss: 1.472 | Train PPL:   4.359\n","\t Val. Loss: 4.399 |  Val. PPL:  81.402\n"]},{"output_type":"stream","name":"stderr","text":["\r 91%|█████████▏| 32/35 [18:41<01:45, 35.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 32 | Time: 0m 35s\n","\tTrain Loss: 1.480 | Train PPL:   4.392\n","\t Val. Loss: 4.401 |  Val. PPL:  81.515\n"]},{"output_type":"stream","name":"stderr","text":["\r 94%|█████████▍| 33/35 [19:16<01:09, 34.98s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 33 | Time: 0m 34s\n","\tTrain Loss: 1.429 | Train PPL:   4.173\n","\t Val. Loss: 4.376 |  Val. PPL:  79.555\n"]},{"output_type":"stream","name":"stderr","text":["\r 97%|█████████▋| 34/35 [19:51<00:35, 35.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 34 | Time: 0m 35s\n","\tTrain Loss: 1.366 | Train PPL:   3.918\n","\t Val. Loss: 4.389 |  Val. PPL:  80.554\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 35/35 [20:26<00:00, 35.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 35 | Time: 0m 35s\n","\tTrain Loss: 1.299 | Train PPL:   3.667\n","\t Val. Loss: 4.512 |  Val. PPL:  91.096\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["best_valid_loss = float('inf')\n","\n","train_losses = []\n","test_losses = []\n","\n","test_phoneme_accs = []\n","\n","epochs = []\n","\n","for epoch in tqdm(range(N_EPOCHS)):\n","    \n","    start_time = time.time()\n","    \n","    train_loss = train(model, train_loader, optimizer, vocab_criterion, index_criterion, CLIP)\n","    metrics = evaluate(model, eval_loader, vocab_criterion, index_criterion)\n","    valid_loss = metrics['vocab_loss']\n","    \n","    end_time = time.time()\n","    \n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    \n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","\n","    # keep track of numbers we want to plot\n","    train_losses.append(train_loss)\n","    test_losses.append(valid_loss)\n","    test_phoneme_accs.append(metrics['phoneme_acc'])\n","    epochs.append(epoch)\n","\n","    \n","    \n","    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"]},{"cell_type":"code","source":["test_dataset = build_dataset(test_pairs)\n","test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n","evaluate(model, eval_loader, vocab_criterion, index_criterion)"],"metadata":{"id":"_Xy9jPehZWqp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639668986430,"user_tz":300,"elapsed":7222,"user":{"displayName":"Sahas D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFhTlCEcqzOdyxuFJOFIBVlqcxwFeNCZ0oVVfdng=s64","userId":"10479330133775136174"}},"outputId":"cac78f5d-0970-40d5-ebb6-fb5812994423"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'phoneme_acc': 0.11418641978358571,\n"," 'phoneme_bleu': 0.2620238258227077,\n"," 'phoneme_edit': 0.21276660128620858,\n"," 'vocab_loss': 4.511916841779437}"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.plot(epochs, train_losses, 'g', label='Training loss')\n","plt.plot(epochs, test_losses, 'b', label='validation loss')\n","plt.title('Training and Validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"ZvtfINjMqd3J","executionInfo":{"status":"aborted","timestamp":1639667534178,"user_tz":300,"elapsed":168,"user":{"displayName":"Sahas D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFhTlCEcqzOdyxuFJOFIBVlqcxwFeNCZ0oVVfdng=s64","userId":"10479330133775136174"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(epochs, test_phoneme_accs, 'b', label='Validation accuracy')\n","plt.title('Validation accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"gP6tvCxna081","executionInfo":{"status":"aborted","timestamp":1639667534179,"user_tz":300,"elapsed":169,"user":{"displayName":"Sahas D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFhTlCEcqzOdyxuFJOFIBVlqcxwFeNCZ0oVVfdng=s64","userId":"10479330133775136174"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from collections import defaultdict\n","\n","samples = generate_samples(model, eval_loader)\n","len_perf_mapping = defaultdict(lambda: [])\n","\n","\n","for sample in samples:\n","  len_perf_mapping[len(sample['target'])].append(sample['phoneme_accuracy'])\n","\n","lengths = []\n","accs = []\n","\n","for key, val in len_perf_mapping.items():\n","\n","  lengths.append(key)\n","  accs.append(sum(val)/len(val))\n"],"metadata":{"id":"wh4W-Dsfa4In","executionInfo":{"status":"aborted","timestamp":1639667534179,"user_tz":300,"elapsed":169,"user":{"displayName":"Sahas D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFhTlCEcqzOdyxuFJOFIBVlqcxwFeNCZ0oVVfdng=s64","userId":"10479330133775136174"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.bar(lengths, accs, color='b')\n","\n","plt.title('Phoneme length vs Accuracy')\n","plt.xlabel('Lengths')\n","plt.ylabel('Accuracy')\n","plt.show()"],"metadata":{"id":"qK4UNuUFbAiT","executionInfo":{"status":"aborted","timestamp":1639667534179,"user_tz":300,"elapsed":169,"user":{"displayName":"Sahas D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFhTlCEcqzOdyxuFJOFIBVlqcxwFeNCZ0oVVfdng=s64","userId":"10479330133775136174"}}},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"text2phoneme_lstm.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1a1541c693d0472a9be5aa3b7b57f0da":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e7d49009296242778e52c36e25d40450","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_29eccf4430534569958a92a052d86a71","IPY_MODEL_566e5b5dcbe6439fb45bfdc5c5fabe8c","IPY_MODEL_c621b8e8e2d742c080a8e5b3199d8f97"]}},"e7d49009296242778e52c36e25d40450":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"29eccf4430534569958a92a052d86a71":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_dc336f0e6f534ecba29081b578ecd168","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_eee08d6eab2d45389054b7ce49570fdf"}},"566e5b5dcbe6439fb45bfdc5c5fabe8c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5c515fdaca274a65bec45e088ad99133","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":2,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_37b28ef5a3de47e78f16bd5400dce6b1"}},"c621b8e8e2d742c080a8e5b3199d8f97":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_dfb1aaf51bc94b719f9e652f649a918e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2/2 [00:00&lt;00:00,  9.00it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bfa746976e3a46a29fc4493d5552b4b0"}},"dc336f0e6f534ecba29081b578ecd168":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"eee08d6eab2d45389054b7ce49570fdf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5c515fdaca274a65bec45e088ad99133":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"37b28ef5a3de47e78f16bd5400dce6b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dfb1aaf51bc94b719f9e652f649a918e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bfa746976e3a46a29fc4493d5552b4b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"nbformat":4,"nbformat_minor":0}